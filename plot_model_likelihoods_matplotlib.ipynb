{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e905705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1d0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_likelihood_vs_time_mpl(likelihoods, path, session_name, df_orig):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for col in likelihoods.columns:\n",
    "        # Using df_orig to get the body part name from row 0 as your code did\n",
    "        plt.plot(likelihoods.index, likelihoods[col], label=str(df_orig.loc[0, col]), alpha=0.7)\n",
    "    \n",
    "    plt.title(f\"Likelihoods over Time: {session_name}\")\n",
    "    plt.xlabel(\"Frame Index\")\n",
    "    plt.ylabel(\"Likelihood\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{path}/likelihood_vs_time_{session_name}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135f43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_likelihood_dist_pooled_mpl(likelihoods, path, session_name):\n",
    "    # Flatten and round\n",
    "    vals = likelihoods.values.flatten().astype(float)\n",
    "    vals = np.round(vals, 2)\n",
    "    \n",
    "    # Calculate distribution\n",
    "    unique, counts = np.unique(vals, return_counts=True)\n",
    "    probs = counts / counts.sum()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(unique, probs, marker='o', linestyle='-', markersize=2)\n",
    "    plt.title(f\"Pooled Confidence Distribution: {session_name}\")\n",
    "    plt.xlabel(\"Confidence Level\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{path}/likelihood_dist_pooled_{session_name}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0137ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_likelihood_cumdist_pooled_mpl(likelihoods, path, session_name):\n",
    "    vals = sorted(likelihoods.values.flatten().astype(float))\n",
    "    # Cumulative distribution\n",
    "    y = np.arange(1, len(vals) + 1) / len(vals)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(vals, y)\n",
    "    plt.title(f\"Cumulative Confidence: {session_name}\")\n",
    "    plt.xlabel(\"Confidence Level\")\n",
    "    plt.ylabel(\"Cumulative Probability\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{path}/likelihood_cumdist_pooled_{session_name}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "216728c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_likelihood_dist_each_mpl(likelihoods, path, session_name, df_orig):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for col in likelihoods.columns:\n",
    "        vals = np.round(likelihoods[col].astype(float).values, 2)\n",
    "        unique, counts = np.unique(vals, return_counts=True)\n",
    "        probs = counts / counts.sum()\n",
    "        \n",
    "        plt.plot(unique, probs, label=str(df_orig.loc[0, col]), alpha=0.8)\n",
    "\n",
    "    plt.title(f\"Distribution for Each Body Part: {session_name}\")\n",
    "    plt.xlabel(\"Confidence Level\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{path}/likelihood_dist_eachBodyPart_{session_name}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce228e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: SA17_20260114_croppedDLC_HrnetW48_TrackFeb2shuffle1_detector_best-130_snapshot_best-10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3092121/572018389.py:26: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Matplotlib figures in: /home/hice1/saminnaji3/DLC/Evaluation/Figures_20260204_080758__best-130_snapshot_best-10\n",
      "All processing complete.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1. Configuration\n",
    "    path_to_model_videos_folder = \"/home/hice1/saminnaji3/DLC/Model/Track-TA-2026-02-02/videos\"\n",
    "    path_to_evaluation_foler = \"/home/hice1/saminnaji3/DLC/Evaluation\"     \n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 2. Get list of CSV files\n",
    "    csv_dir_all = [d for d in os.listdir(path_to_model_videos_folder) if d.endswith('.csv')]\n",
    "    \n",
    "    if not csv_dir_all:\n",
    "        print(\"No CSV files found in the directory!\")\n",
    "\n",
    "    for csv_dir in csv_dir_all:\n",
    "        print(f\"Processing: {csv_dir}\")\n",
    "\n",
    "        # Create unique folder for this specific CSV's figures\n",
    "        # This prevents figures from different model iterations from overwriting each other\n",
    "        suffix = csv_dir.split(\"_detector\")[1].replace(\".csv\", \"\") if \"_detector\" in csv_dir else \"\"\n",
    "        new_path = os.path.join(path_to_evaluation_foler, f\"Figures_{timestamp}_{suffix}\")\n",
    "        os.makedirs(new_path, exist_ok=True)\n",
    "\n",
    "        csv_path = os.path.join(path_to_model_videos_folder, csv_dir)\n",
    "        \n",
    "        # 3. Load and Clean Data\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Extract likelihood columns (every 3rd column starting from index 3)\n",
    "        likelihood_indices = list(range(3, len(df.columns), 3))\n",
    "        likelihoods = df.iloc[2:, likelihood_indices].copy()\n",
    "        \n",
    "        # Ensure data is numeric (DLC CSVs often read these as objects/strings)\n",
    "        likelihoods = likelihoods.apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "        # Use filename as session name\n",
    "        session_name = csv_dir.replace(\".csv\", \"\")\n",
    "\n",
    "        # 4. Generate Plots\n",
    "        print(f\"Generating Matplotlib figures in: {new_path}\")\n",
    "        \n",
    "        plot_likelihood_vs_time_mpl(likelihoods, new_path, session_name, df)\n",
    "        plot_likelihood_dist_pooled_mpl(likelihoods, new_path, session_name)\n",
    "        plot_likelihood_cumdist_pooled_mpl(likelihoods, new_path, session_name)\n",
    "        plot_likelihood_dist_each_mpl(likelihoods, new_path, session_name, df)\n",
    "\n",
    "    print(\"All processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLabCut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
